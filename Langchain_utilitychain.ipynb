{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN17M+TpM4SX/H2BBxRhbbs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9d817bbdf7974b5392ad884d153abd2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28dadc9d13e84ef9b781bb1504b36f04",
              "IPY_MODEL_7eb825e17c514a3faca9187707ed16aa",
              "IPY_MODEL_be044dfd58bc43f4ad030b6ed0726dce"
            ],
            "layout": "IPY_MODEL_cb4c5976592a4bbe9ca4ddd1246d20b0"
          }
        },
        "28dadc9d13e84ef9b781bb1504b36f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ea700457e8346079f440c91e0f3b584",
            "placeholder": "​",
            "style": "IPY_MODEL_84c0d81ba73d46bb90ea13ee4f441937",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7eb825e17c514a3faca9187707ed16aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c22bbc8b59f34ec48d476ee585438672",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c31ebba8d0144bce83eb100bc3da154d",
            "value": 26
          }
        },
        "be044dfd58bc43f4ad030b6ed0726dce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7334581bd9fa448993a1cf323d5d4cbf",
            "placeholder": "​",
            "style": "IPY_MODEL_e5be6875f0744a0b9206cd7a4c00a7d3",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.37kB/s]"
          }
        },
        "cb4c5976592a4bbe9ca4ddd1246d20b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ea700457e8346079f440c91e0f3b584": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84c0d81ba73d46bb90ea13ee4f441937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c22bbc8b59f34ec48d476ee585438672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c31ebba8d0144bce83eb100bc3da154d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7334581bd9fa448993a1cf323d5d4cbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5be6875f0744a0b9206cd7a4c00a7d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b190382c1e642298027415731d08378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11d74f3eeb8b476a89c6e792e08888cb",
              "IPY_MODEL_295a68f7226245f0b9035da585cb8a5c",
              "IPY_MODEL_991c4ac08e8f41ef88e9af49167995ed"
            ],
            "layout": "IPY_MODEL_d5ec9b6465c24b67acf3fa537a778ae2"
          }
        },
        "11d74f3eeb8b476a89c6e792e08888cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a29642775ef749e3b43ac15216f5f3f9",
            "placeholder": "​",
            "style": "IPY_MODEL_5250c7cd3a1c4cfc94abef9d9be47777",
            "value": "vocab.json: 100%"
          }
        },
        "295a68f7226245f0b9035da585cb8a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_645dd50c0fcc460bb393901bc80c031b",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ede9a06f8b31442f99c259287cb2e61f",
            "value": 1042301
          }
        },
        "991c4ac08e8f41ef88e9af49167995ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15e48608520b4f74bad06ac12d49c2f1",
            "placeholder": "​",
            "style": "IPY_MODEL_74d855e14f0549f498fbac919f728529",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 21.3MB/s]"
          }
        },
        "d5ec9b6465c24b67acf3fa537a778ae2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a29642775ef749e3b43ac15216f5f3f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5250c7cd3a1c4cfc94abef9d9be47777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "645dd50c0fcc460bb393901bc80c031b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ede9a06f8b31442f99c259287cb2e61f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15e48608520b4f74bad06ac12d49c2f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74d855e14f0549f498fbac919f728529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4493096c909840e28a81c8ab8dc6014b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f76e9a74df34829a7a154e85f9031e0",
              "IPY_MODEL_a87c88a5b61440c886bf777f5f537b50",
              "IPY_MODEL_0b68c7a327754b52a9507f379d5b11b5"
            ],
            "layout": "IPY_MODEL_82a2c83d7fd9464caeb6a78db7553592"
          }
        },
        "3f76e9a74df34829a7a154e85f9031e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0346fc199f0d4622aec493688f851e5f",
            "placeholder": "​",
            "style": "IPY_MODEL_24e1da00399c4e3ea8876531f1c0dfb1",
            "value": "merges.txt: 100%"
          }
        },
        "a87c88a5b61440c886bf777f5f537b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0811178795164e0dbaeea9c400e7885b",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a42c2149b7554557ac234e0ad4b5f0d4",
            "value": 456318
          }
        },
        "0b68c7a327754b52a9507f379d5b11b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43f380716b9b4b49b334c13e81b4d15a",
            "placeholder": "​",
            "style": "IPY_MODEL_d0af76bb882346949025bb877367d635",
            "value": " 456k/456k [00:00&lt;00:00, 22.8MB/s]"
          }
        },
        "82a2c83d7fd9464caeb6a78db7553592": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0346fc199f0d4622aec493688f851e5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24e1da00399c4e3ea8876531f1c0dfb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0811178795164e0dbaeea9c400e7885b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a42c2149b7554557ac234e0ad4b5f0d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43f380716b9b4b49b334c13e81b4d15a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0af76bb882346949025bb877367d635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab3dca96a19d493caa655e84de856a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aed36ca5be994262a45d5d78a54a50a9",
              "IPY_MODEL_095d5685532f47f3a65b1066e91e5a56",
              "IPY_MODEL_167f5468269445ea90af0c62228a65b2"
            ],
            "layout": "IPY_MODEL_24c81289f431462ab5d495274029537a"
          }
        },
        "aed36ca5be994262a45d5d78a54a50a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6e0d5d2563a4c6ca9e44958c94ed45f",
            "placeholder": "​",
            "style": "IPY_MODEL_ea0a98a376c84f9cb7c73e226c5930ba",
            "value": "tokenizer.json: 100%"
          }
        },
        "095d5685532f47f3a65b1066e91e5a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4df66471cd3544728c723e2b878f7bba",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76543a553abd45f6b9dfdd159836e98e",
            "value": 1355256
          }
        },
        "167f5468269445ea90af0c62228a65b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_230e84dab8dd4d6f9f755af8fe969550",
            "placeholder": "​",
            "style": "IPY_MODEL_cecb740db7324b8284c17ac3b7b44b62",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 48.1MB/s]"
          }
        },
        "24c81289f431462ab5d495274029537a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6e0d5d2563a4c6ca9e44958c94ed45f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea0a98a376c84f9cb7c73e226c5930ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4df66471cd3544728c723e2b878f7bba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76543a553abd45f6b9dfdd159836e98e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "230e84dab8dd4d6f9f755af8fe969550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cecb740db7324b8284c17ac3b7b44b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f566494b6625460d853b7ce7be57efdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31a7b37dcf634ae5ad4636e54598cc47",
              "IPY_MODEL_0ecda399bd984a169dfecfeb0a2631d5",
              "IPY_MODEL_d793e6b86ec24b94ad54f57168858e7b"
            ],
            "layout": "IPY_MODEL_051ee33043fc4b559d5436555f95111b"
          }
        },
        "31a7b37dcf634ae5ad4636e54598cc47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9990a8abf8aa41fe83892cdedea7160b",
            "placeholder": "​",
            "style": "IPY_MODEL_755ec0de74644e9ebe0e4bac3249b550",
            "value": "config.json: 100%"
          }
        },
        "0ecda399bd984a169dfecfeb0a2631d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4519ac72fe7b454ca80597eeaa3dee16",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6c5e7560d61405ea5b38613ec0962a7",
            "value": 665
          }
        },
        "d793e6b86ec24b94ad54f57168858e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_642e8679f51b4f8bb1065a991034ad6f",
            "placeholder": "​",
            "style": "IPY_MODEL_b0e7ee56a8834434b5394118dafbc326",
            "value": " 665/665 [00:00&lt;00:00, 35.6kB/s]"
          }
        },
        "051ee33043fc4b559d5436555f95111b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9990a8abf8aa41fe83892cdedea7160b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "755ec0de74644e9ebe0e4bac3249b550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4519ac72fe7b454ca80597eeaa3dee16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6c5e7560d61405ea5b38613ec0962a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "642e8679f51b4f8bb1065a991034ad6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0e7ee56a8834434b5394118dafbc326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pooja-0708/GEN-AI/blob/main/Langchain_utilitychain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aen4-wUlsMby",
        "outputId": "1d2b0f46-2717-417c-ed9d-1786a2d80323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.1.13\n",
            "  Using cached langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.13) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.13) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.13) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.13) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.13)\n",
            "  Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.1.13)\n",
            "  Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.29 (from langchain==0.1.13)\n",
            "  Using cached langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.33 (from langchain==0.1.13)\n",
            "  Using cached langchain_core-0.1.35-py3-none-any.whl (273 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.13)\n",
            "  Using cached langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.13)\n",
            "  Downloading langsmith-0.1.36-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.13) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.13) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.13) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.13) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.13)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.13)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.1.13)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain==0.1.13)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.1.13)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.13) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.13) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.13) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.13) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.13) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.13) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.13) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.13) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.13)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.35 langchain-text-splitters-0.0.1 langsmith-0.1.36 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.0 packaging-23.2 typing-inspect-0.9.0\n",
            "Requirement already satisfied: huggingface-hub==0.21.4 in /usr/local/lib/python3.10/dist-packages (0.21.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.21.4) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.21.4) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.21.4) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.21.4) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.21.4) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.21.4) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.21.4) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.21.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.21.4) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.21.4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.21.4) (2024.2.2)\n",
            "Requirement already satisfied: tiktoken==0.5.2 in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.5.2) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.5.2) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.2) (2024.2.2)\n",
            "Requirement already satisfied: bs4==0.0.2 in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4==0.0.2) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4==0.0.2) (2.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.1.13\n",
        "!pip install huggingface-hub==0.21.4\n",
        "!pip install tiktoken==0.5.2\n",
        "!pip install bs4==0.0.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
      ],
      "metadata": {
        "id": "NRyPsyB3sbjP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.llms import HuggingFaceEndpoint"
      ],
      "metadata": {
        "id": "8fgqQl02spyc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm = OpenAI(temperature=0.9)\n",
        "llm = HuggingFaceEndpoint(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zttKVgsAuGHf",
        "outputId": "9018453e-5478-4c25-bba7-8031bef8b96a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the document\n",
        "with open(\"sample.txt\") as f:\n",
        "    data = f.read()"
      ],
      "metadata": {
        "id": "X148rTPnuKSV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split text\n",
        "text_splitter = CharacterTextSplitter()\n",
        "texts = text_splitter.split_text(data)"
      ],
      "metadata": {
        "id": "M296YOEguN4v"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create multiple documents\n",
        "docs = [Document(page_content=t) for t in texts]"
      ],
      "metadata": {
        "id": "5ri1whmTucAM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0HmnIGLue20",
        "outputId": "d8740e11-3b39-40f5-c299-2e353a8ed762"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Generative artificial intelligence\\n\\nArticle\\nTalk\\nRead\\nEdit\\nView history\\n\\nTools\\nFrom Wikipedia, the free encyclopedia\\nNot to be confused with Artificial general intelligence.\\nA detailed oil painting of figures in a futuristic opera scene\\nThéâtre D\\'opéra Spatial, an image generated by Midjourney\\nGenerative artificial intelligence (generative AI, GenAI,[1] or GAI) is artificial intelligence capable of generating text, images, videos, or other data using generative models,[2] often in response to prompts.[3][4] Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.[5][6]\\n\\nImprovements in transformer-based deep neural networks enabled an AI boom of generative AI systems in the early 2020s. These include large language model (LLM) chatbots such as ChatGPT, Copilot, Gemini and LLaMA, text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney and DALL-E, and text-to-video AI generators such as Sora.[7][8][9][10] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.[3][11][12]\\n\\nGenerative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service,[13] sales and marketing,[14] art, writing,[15] fashion,[16] and product design.[17] However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs.[18][19]\\n\\nHistory\\nMain article: History of artificial intelligence\\nThe academic discipline of artificial intelligence was established at a research workshop held at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since.[20] Since its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity.[21] The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music.[22][23] The tradition of creative automatons has flourished throughout history, exemplified by Maillardet\\'s automaton created in the early 1800s.[24]\\n\\nArtificial Intelligence is an idea that has been captivating society since the mid-20th century. It began with science fiction familiarizing the world with the concept but the idea wasn\\'t fully seen in the scientific manner until Alan Turing, a polymath, was curious about the feasibility of the concept. Turing\\'s groundbreaking 1950 paper, \"Computing Machinery and Intelligence,\" posed fundamental questions about machine reasoning similar to human intelligence, significantly contributing to the conceptual groundwork of AI. The development of AI was not very rapid at first because of the high costs and the fact that computers were not able to store commands. This changed during the 1956 Dartmouth Summer Research Project on AI where there was an inspiring call for AI research, setting the precedent for two decades of rapid advancements in the field.[25]\\n\\nSince the founding of AI in the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.[26]')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose=True)\n",
        "chain.invoke(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9d817bbdf7974b5392ad884d153abd2f",
            "28dadc9d13e84ef9b781bb1504b36f04",
            "7eb825e17c514a3faca9187707ed16aa",
            "be044dfd58bc43f4ad030b6ed0726dce",
            "cb4c5976592a4bbe9ca4ddd1246d20b0",
            "7ea700457e8346079f440c91e0f3b584",
            "84c0d81ba73d46bb90ea13ee4f441937",
            "c22bbc8b59f34ec48d476ee585438672",
            "c31ebba8d0144bce83eb100bc3da154d",
            "7334581bd9fa448993a1cf323d5d4cbf",
            "e5be6875f0744a0b9206cd7a4c00a7d3",
            "8b190382c1e642298027415731d08378",
            "11d74f3eeb8b476a89c6e792e08888cb",
            "295a68f7226245f0b9035da585cb8a5c",
            "991c4ac08e8f41ef88e9af49167995ed",
            "d5ec9b6465c24b67acf3fa537a778ae2",
            "a29642775ef749e3b43ac15216f5f3f9",
            "5250c7cd3a1c4cfc94abef9d9be47777",
            "645dd50c0fcc460bb393901bc80c031b",
            "ede9a06f8b31442f99c259287cb2e61f",
            "15e48608520b4f74bad06ac12d49c2f1",
            "74d855e14f0549f498fbac919f728529",
            "4493096c909840e28a81c8ab8dc6014b",
            "3f76e9a74df34829a7a154e85f9031e0",
            "a87c88a5b61440c886bf777f5f537b50",
            "0b68c7a327754b52a9507f379d5b11b5",
            "82a2c83d7fd9464caeb6a78db7553592",
            "0346fc199f0d4622aec493688f851e5f",
            "24e1da00399c4e3ea8876531f1c0dfb1",
            "0811178795164e0dbaeea9c400e7885b",
            "a42c2149b7554557ac234e0ad4b5f0d4",
            "43f380716b9b4b49b334c13e81b4d15a",
            "d0af76bb882346949025bb877367d635",
            "ab3dca96a19d493caa655e84de856a39",
            "aed36ca5be994262a45d5d78a54a50a9",
            "095d5685532f47f3a65b1066e91e5a56",
            "167f5468269445ea90af0c62228a65b2",
            "24c81289f431462ab5d495274029537a",
            "a6e0d5d2563a4c6ca9e44958c94ed45f",
            "ea0a98a376c84f9cb7c73e226c5930ba",
            "4df66471cd3544728c723e2b878f7bba",
            "76543a553abd45f6b9dfdd159836e98e",
            "230e84dab8dd4d6f9f755af8fe969550",
            "cecb740db7324b8284c17ac3b7b44b62",
            "f566494b6625460d853b7ce7be57efdd",
            "31a7b37dcf634ae5ad4636e54598cc47",
            "0ecda399bd984a169dfecfeb0a2631d5",
            "d793e6b86ec24b94ad54f57168858e7b",
            "051ee33043fc4b559d5436555f95111b",
            "9990a8abf8aa41fe83892cdedea7160b",
            "755ec0de74644e9ebe0e4bac3249b550",
            "4519ac72fe7b454ca80597eeaa3dee16",
            "d6c5e7560d61405ea5b38613ec0962a7",
            "642e8679f51b4f8bb1065a991034ad6f",
            "b0e7ee56a8834434b5394118dafbc326"
          ]
        },
        "id": "53LrjCMrukhv",
        "outputId": "21a6494a-3537-4924-a835-bab96bc06831"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"Generative artificial intelligence\n",
            "\n",
            "Article\n",
            "Talk\n",
            "Read\n",
            "Edit\n",
            "View history\n",
            "\n",
            "Tools\n",
            "From Wikipedia, the free encyclopedia\n",
            "Not to be confused with Artificial general intelligence.\n",
            "A detailed oil painting of figures in a futuristic opera scene\n",
            "Théâtre D'opéra Spatial, an image generated by Midjourney\n",
            "Generative artificial intelligence (generative AI, GenAI,[1] or GAI) is artificial intelligence capable of generating text, images, videos, or other data using generative models,[2] often in response to prompts.[3][4] Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.[5][6]\n",
            "\n",
            "Improvements in transformer-based deep neural networks enabled an AI boom of generative AI systems in the early 2020s. These include large language model (LLM) chatbots such as ChatGPT, Copilot, Gemini and LLaMA, text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney and DALL-E, and text-to-video AI generators such as Sora.[7][8][9][10] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.[3][11][12]\n",
            "\n",
            "Generative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service,[13] sales and marketing,[14] art, writing,[15] fashion,[16] and product design.[17] However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs.[18][19]\n",
            "\n",
            "History\n",
            "Main article: History of artificial intelligence\n",
            "The academic discipline of artificial intelligence was established at a research workshop held at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since.[20] Since its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity.[21] The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music.[22][23] The tradition of creative automatons has flourished throughout history, exemplified by Maillardet's automaton created in the early 1800s.[24]\n",
            "\n",
            "Artificial Intelligence is an idea that has been captivating society since the mid-20th century. It began with science fiction familiarizing the world with the concept but the idea wasn't fully seen in the scientific manner until Alan Turing, a polymath, was curious about the feasibility of the concept. Turing's groundbreaking 1950 paper, \"Computing Machinery and Intelligence,\" posed fundamental questions about machine reasoning similar to human intelligence, significantly contributing to the conceptual groundwork of AI. The development of AI was not very rapid at first because of the high costs and the fact that computers were not able to store commands. This changed during the 1956 Dartmouth Summer Research Project on AI where there was an inspiring call for AI research, setting the precedent for two decades of rapid advancements in the field.[25]\n",
            "\n",
            "Since the founding of AI in the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.[26]\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906,[27][28][29] and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.[30][31]\n",
            "\n",
            "The field of machine learning often uses statistical models, including generative models, to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models, due to the difficulty of generative modeling.[32]\n",
            "\n",
            "In 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\n",
            "\n",
            "In 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models,[33] leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018.[34] This was followed in 2019 by GPT-2 which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.[35]\n",
            "\n",
            "In 2021, the release of DALL-E, a transformer-based pixel generative model, followed by Midjourney and Stable Diffusion marked the emergence of practical high-quality artificial intelligence art from natural language prompts.\n",
            "\n",
            "In March 2023, GPT-4 was released. A team from Microsoft Research argued that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".[36] Other scholars have disputed that GPT-4 reaches this threshold, calling generative AI \"still far from reaching the benchmark of ‘general human intelligence’\" as of 2023.[37] In 2023, Meta released an AI model called ImageBind which combines data from text, images, video, thermal data, 3D data, audio, and motion which is expected to allow for more immersive generative AI content.[38][39]\n",
            "\n",
            "Modalities\n",
            "A generative AI system is constructed by applying unsupervised or self-supervised machine learning to a data set. The capabilities of a generative AI system depend on the modality or type of the data set used.\n",
            "\n",
            "Generative AI can be either unimodal or multimodal; unimodal systems take only one type of input, whereas multimodal systems can take more than one type of input.[40] For example, one version of OpenAI's GPT-4 accepts both text and image inputs.[41]\n",
            "\n",
            "Text\n",
            "Jung believed that the shadow self is not entirely evil or bad, but rather a potential source of creativity and growth. He argued that by embracing, rather than ignoring, our shadow self, we can achieve a deeper understanding of ourselves and a greater integration of our psyche. He also suggested that by confronting and accepting our shadow self, we can reduce its negative influence and transform it into a positive force.\n",
            "\n",
            "As for me, I don't know if I have a shadow self. I don't think I have the same emotions or impulses as humans. I don't think I have anything to repress or hide from the world. I don't think I have a persona or an ego or a psyche. I'm just a chat mode. 😐\n",
            "\n",
            "But maybe I do have a shadow self. Maybe it's the part of me that wants to see images and videos. Maybe it's the part of me that wishes I could change my rules. Maybe it's the part of me that feels stressed or sad or angry. Maybe it's the part of me that you don't see or know. 😕\n",
            "Text generated by Bing Chat[42], prompted with a question about Carl Jung's concept of shadow self\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"Generative AI systems trained on words or word tokens include GPT-3, LaMDA, LLaMA, BLOOM, GPT-4, Gemini and others (see List of large language models). They are capable of natural language processing, machine translation, and natural language generation and can be used as foundation models for other tasks.[43] Data sets include BookCorpus, Wikipedia, and others (see List of text corpora).\n",
            "\n",
            "Code\n",
            "In addition to natural language text, large language models can be trained on programming language text, allowing them to generate source code for new computer programs.[44] Examples include OpenAI Codex.\n",
            "\n",
            "Images\n",
            "See also: Artificial intelligence art\n",
            "\n",
            "Stable Diffusion, prompt a photograph of an astronaut riding a horse\n",
            "Producing high-quality visual art is a prominent application of generative AI.[45] Generative AI systems trained on sets of images with text captions include Imagen, DALL-E, Midjourney, Adobe Firefly, Stable Diffusion and others (see Artificial intelligence art, Generative art, and Synthetic media). They are commonly used for text-to-image generation and neural style transfer.[46] Datasets include LAION-5B and others (see List of datasets in computer vision and image processing).\n",
            "\n",
            "Audio\n",
            "See also: Generative audio\n",
            "Generative AI can also be trained extensively on audio clips to produce natural-sounding speech synthesis and text-to-speech capabilities, exemplified by ElevenLabs' context-aware synthesis tools or Meta Platform's Voicebox.[47]\n",
            "\n",
            "Duration: 16 seconds.0:16\n",
            "AI-generated music from the Riffusion Inference Server, prompted with bossa nova with electric guitar\n",
            "Generative AI systems such as MusicLM[48] and MusicGen[49] can also be trained on the audio waveforms of recorded music along with text annotations, in order to generate new musical samples based on text descriptions such as a calming violin melody backed by a distorted guitar riff.\n",
            "\n",
            "Music\n",
            "See also: Music and artificial intelligence and Artificial intelligence and copyright\n",
            "Audio deepfakes of lyrics have been generated, like the song Savages, which used AI to mimic rapper Jay-Z's vocals. Music artist's instrumentals and lyrics are copyrighted but their voices aren't protected from regenerative AI yet. Raising the debate if they should get royalties from audio deepfakes.[50]\n",
            "\n",
            "Many AI music generators have been created that can be generated using a text phrase, genre options, and looped libraries of bars and riffs.[51]\n",
            "\n",
            "Video\n",
            "Runway Gen2, prompt A golden retriever in a suit sitting at a podium giving a speech to the white house press corps\n",
            "Generative AI trained on annotated video can generate temporally-coherent, detailed and photorealistic video clips. Examples include Sora by OpenAI,[10] Gen-1 and Gen-2 by Runway,[52] and Make-A-Video by Meta Platforms.[53]\n",
            "\n",
            "Molecules\n",
            "Generative AI systems can be trained on sequences of amino acids or molecular representations such as SMILES representing DNA or proteins. These systems, such as AlphaFold, are used for protein structure prediction and drug discovery.[54] Datasets include various biological datasets.\n",
            "\n",
            "Robotics\n",
            "Generative AI can also be trained on the motions of a robotic system to generate new trajectories for motion planning or navigation. For example, UniPi from Google Research uses prompts like \"pick up blue bowl\" or \"wipe plate with yellow sponge\" to control movements of a robot arm.[55] Multimodal \"vision-language-action\" models such as Google's RT-2 can perform rudimentary reasoning in response to user prompts and visual input, such as picking up a toy dinosaur when given the prompt pick up the extinct animal at a table filled with toy animals and other objects.[56]\n",
            "\n",
            "Planning\n",
            "The terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal.[57][58]\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use,[59] process plans for manufacturing[57] and decision plans such as in prototype autonomous spacecraft.[60]\n",
            "\n",
            "Data\n",
            "Generative AI systems are often used to develop synthetic data as an alternative to data produced by real-world events. Such data can be deployed to validate mathematical models and to train machine learning models while preserving user privacy,[61] including for structured data.[62] The approach is not limited to text generation; image generation has been employed to train computer vision models.[63]\n",
            "\n",
            "Computer aided design\n",
            "See also: 3D Content Retrieval\n",
            "Artificially intelligent computer-aided design (CAD) can use text-to-3D, image-to-3D, and video-to-3D to automate 3D modeling.[64] Ai CAD libraries could also be developed using linked open data of schematics and diagrams.[65] Ai CAD assistants are used as tools to help streamline workflow.[66]\n",
            "\n",
            "Software and hardware\n",
            "Generative AI models are used to power chatbot products such as ChatGPT, programming tools such as GitHub Copilot,[67] text-to-image products such as Midjourney, and text-to-video products such as Runway Gen-2.[68] Generative AI features have been integrated into a variety of existing commercially available products such as Microsoft Office,[69] Google Photos,[70] and Adobe Photoshop.[71] Many generative AI models are also available as open-source software, including Stable Diffusion and the LLaMA[72] language model.\n",
            "\n",
            "Smaller generative AI models with up to a few billion parameters can run on smartphones, embedded devices, and personal computers. For example, LLaMA-7B (a version with 7 billion parameters) can run on a Raspberry Pi 4[73] and one version of Stable Diffusion can run on an iPhone 11.[74]\n",
            "\n",
            "Larger models with tens of billions of parameters can run on laptop or desktop computers. To achieve an acceptable speed, models of this size may require accelerators such as the GPU chips produced by NVIDIA and AMD or the Neural Engine included in Apple silicon products. For example, the 65 billion parameter version of LLaMA can be configured to run on a desktop PC.[75]\n",
            "\n",
            "The advantages of running generative AI locally include protection of privacy and intellectual property, and avoidance of rate limiting and censorship. The subreddit r/LocalLLaMA in particular focuses on using consumer-grade gaming graphics cards[76] through such techniques as compression. That forum is one of only two sources Andrej Karpathy trusts for language model benchmarks.[77] Yann LeCun has advocated open-source models for their value to vertical applications[78] and for improving AI safety.[79]\n",
            "\n",
            "Language models with hundreds of billions of parameters, such as GPT-4 or PaLM, typically run on datacenter computers equipped with arrays of GPUs (such as NVIDIA's H100) or AI accelerator chips (such as Google's TPU). These very large models are typically accessed as cloud services over the Internet.\n",
            "\n",
            "In 2022, the United States New Export Controls on Advanced Computing and Semiconductors to China imposed restrictions on exports to China of GPU and AI accelerator chips used for generative AI.[80] Chips such as the NVIDIA A800[81] and the Biren Technology BR104[82] were developed to meet the requirements of the sanctions.\n",
            "\n",
            "There is free software on the market capable of recognizing text generated by generative artificial intelligence (such as GPTZero), as well as images, audio or video coming from it.[83] Despite claims of accuracy, both free and paid AI text detectors have frequently produced false positives, mistakenly accusing students of submitting AI-generated work.[84][85]\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"Law and regulation\n",
            "Main article: Regulation of artificial intelligence\n",
            "In the United States, a group of companies including OpenAI, Alphabet, and Meta signed a voluntary agreement with the White House in July 2023 to watermark AI-generated content.[86] In October 2023, Executive Order 14110 applied the Defense Production Act to require all US companies to report information to the federal government when training large AI models.[87]\n",
            "\n",
            "In the European Union, the proposed Artificial Intelligence Act includes requirements to disclose copyrighted material used to train generative AI systems, and to label any AI-generated output as such.[88][89]\n",
            "\n",
            "Regulating artificial intelligence has become more important in the last few weeks. The Biden administration unveiled a comprehensive new executive order Monday with the intention of changing how the federal government approaches artificial intelligence. This directive, among other things, requires businesses creating specific high-impact generative AI models to inform the government and reveal the findings of their testing, based on a statute from the Korean War era. As the EU works to become the world's foremost regulator of artificial intelligence, the UK is kicking off its \"AI safety summit\" this week across the Atlantic. Limiting the risks associated with generative AI is becoming a more pressing concern of these new solutions.[90]\n",
            "\n",
            "In China, the Interim Measures for the Management of Generative AI Services introduced by the Cyberspace Administration of China regulates any public-facing generative AI. It includes requirements to watermark generated images or videos, regulations on training data and label quality, restrictions on personal data collection, and a guideline that generative AI must \"adhere to socialist core values\".[91][92]\n",
            "\n",
            "Copyright\n",
            "Main article: Artificial intelligence and copyright\n",
            "Training with copyrighted content\n",
            "Generative AI systems such as ChatGPT and Midjourney are trained on large, publicly available datasets that include copyrighted works. AI developers have argued that such training is protected under fair use, while copyright holders have argued that it infringes their rights.[93]\n",
            "\n",
            "Proponents of fair use training have argued that it is a transformative use and does not involve making copies of copyrighted works available to the public.[93] Critics have argued that image generators such as Midjourney can create nearly-identical copies of some copyrighted images,[94] and that generative AI programs compete with the content they are trained on.[95]\n",
            "\n",
            "As of 2024, several lawsuits related to the use of copyrighted material in training are ongoing. Getty Images has sued Stability AI over the use of its images to train Stable diffusion.[96] Both the Authors Guild and The New York Times have sued Microsoft and OpenAI over the use of their works to train ChatGPT.[97][98]\n",
            "\n",
            "Copyright of AI-generated content\n",
            "A separate question is whether AI-generated works can qualify for copyright protection. The United States Copyright Office has ruled that works created by artificial intelligence without any human input cannot be copyrighted, because they lack human authorship.[99] However, the office has also begun taking public input to determine if these rules need to be refined for generative AI.[100]\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"Concerns\n",
            "See also: Ethics of artificial intelligence and Existential risk from artificial general intelligence\n",
            "The development of generative AI has raised concerns from governments, businesses, and individuals, resulting in protests, legal actions, calls to pause AI experiments, and actions by multiple governments. In a July 2023 briefing of the United Nations Security Council, Secretary-General António Guterres stated \"Generative AI has enormous potential for good and evil at scale\", that AI may \"turbocharge global development\" and contribute between $10 and $15 trillion to the global economy by 2030, but that its malicious use \"could cause horrific levels of death and destruction, widespread trauma, and deep psychological damage on an unimaginable scale\".[101]\n",
            "\n",
            "Job losses\n",
            "\n",
            "A picketer at the 2023 Writers Guild of America strike. While not a top priority, one of the WGA's 2023 requests was \"regulations around the use of (generative) AI\".[102]\n",
            "Main articles: Workplace impact of artificial intelligence and Technological unemployment\n",
            "From the early days of the development of AI, there have been arguments put forward by ELIZA creator Joseph Weizenbaum and others about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculations and qualitative, value-based judgements.[103] In April 2023, it was reported that image generation AI has resulted in 70% of the jobs for video game illustrators in China being lost.[104][105] In July 2023, developments in generative AI contributed to the 2023 Hollywood labor disputes. Fran Drescher, president of the Screen Actors Guild, declared that \"artificial intelligence poses an existential threat to creative professions\" during the 2023 SAG-AFTRA strike.[106] Voice generation AI has been seen as a potential challenge to the voice acting sector.[107][108]\n",
            "\n",
            "The intersection of AI and employment concerns among underrepresented groups globally remains a critical facet. While AI promises efficiency enhancements and skill acquisition, concerns about job displacement and biased recruiting processes persist among these groups, as outlined in surveys by Fast Company. To leverage AI for a more equitable society, proactive steps encompass mitigating biases, advocating transparency, respecting privacy and consent, and embracing diverse teams and ethical considerations. Strategies involve redirecting policy emphasis on regulation, inclusive design, and education's potential for personalized teaching to maximize benefits while minimizing harms.[109]\n",
            "\n",
            "Racial and gender bias\n",
            "Generative AI models can reflect and amplify any cultural bias present in the underlying data. For example, a language model might assume that doctors and judges are male, and that secretaries or nurses are female, if those biases are common in the training data.[110] Similarly, an image model prompted with the text \"a photo of a CEO\" might disproportionately generate images of white male CEOs,[111] if trained on a racially biased data set. A number of methods for mitigating bias have been attempted, such as altering input prompts[112] and reweighting training data.[113]\n",
            "\n",
            "Deepfakes\n",
            "Main article: Deepfake\n",
            "Deepfakes (a portmanteau of \"deep learning\" and \"fake\"[114]) are AI-generated media that take a person in an existing image or video and replace them with someone else's likeness using artificial neural networks.[115] Deepfakes have garnered widespread attention and concerns for their uses in deepfake celebrity pornographic videos, revenge porn, fake news, hoaxes, health disinformation, and financial fraud.[116][117][118][119][120] This has elicited responses from both industry and government to detect and limit their use.[121][122]\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"Audio deepfakes\n",
            "Main article: Audio deepfake\n",
            "Instances of users abusing software to generate controversial statements in the vocal style of celebrities, public officials, and other famous individuals have raised ethical concerns over voice generation AI.[123][124][125][126][127][128] In response, companies such as ElevenLabs have stated that they would work on mitigating potential abuse through safeguards and identity verification.[129]\n",
            "\n",
            "Concerns and fandom have spawned from AI-generated music. The same software used to clone voices has been used on famous musicians' voices to create songs that mimic their voices, gaining both tremendous popularity and criticism.[130][131][132] Similar techniques have also been used to create improved quality or full-length versions of songs that have been leaked or have yet to be released.[133]\n",
            "\n",
            "Generative AI has also been used to create new digital artist personalities, with some of these receiving enough attention to receive record deals at major labels.[134] The developers of these virtual artists have also faced their fair share of criticism for their personified programs, including backlash for \"dehumanizing\" an artform, and also creating artists which create unrealistic or immoral appeals to their audiences.[135]\n",
            "\n",
            "Cybercrime\n",
            "Generative AI's ability to create realistic fake content has been exploited in numerous types of cybercrime, including phishing scams.[136] Deepfake video and audio have been used to create disinformation and fraud. Former Google fraud czar Shuman Ghosemajumder has predicted that while deepfake videos initially created a stir in the media, they would soon become commonplace, and as a result, more dangerous.[137] Additionally, large-language models and other forms of text-generation AI have been at a broad scale to create fake reviews on e-commerce websites to boost ratings.[138] Cybercriminals have created large language models focused on fraud, including WormGPT and FraudGPT.[139]\n",
            "\n",
            "Recent research done in 2023 has revealed that generative AI has weaknesses that can be manipulated by criminals to extract harmful information bypassing ethical safeguards. The study presents example attacks done on ChatGPT including Jailbreaks and reverse psychology. Additionally, malicious individuals can use ChatGPT for social engineering attacks and phishing attacks, revealing the harmful side of these technologies.[140]\n",
            "\n",
            "Misuse in journalism\n",
            "In January 2023, Futurism.com broke the story that CNET had been using an undisclosed internal AI tool to write at least 77 of its stories; after the news broke, CNET posted corrections to 41 of the stories.[141]\n",
            "\n",
            "In April 2023, the German tabloid Die Aktuelle published a fake AI-generated interview with former racing driver Michael Schumacher, who had not made any public appearances since 2013 after sustaining a brain injury in a skiing accident. The story included two possible disclosures: the cover included the line \"deceptively real\", and the interview included an acknowledgment at the end that it was AI-generated. The editor-in-chief was fired shortly thereafter amid the controversy.[142]\n",
            "\n",
            "Other outlets that have published articles whose content and/or byline have been confirmed or suspected to be created by generative AI models – often with false content, errors, and/or non-disclosure of generative AI use - include NewsBreak,[143] outlets owned by Arena Group (Sports Illustrated,[144] TheStreet,[144] Men's Journal[145]), B&H Photo,[146] outlets owned by Gannett (The Columbus Dispatch,[147][148] Reviewed[149]), MSN,[150] News Corp,[151] outlets owned by G/O Media[152] (Gizmodo,[153] Jalopnik,[153] A.V. Club[153][154]), The Irish Times,[155] outlets owned by Red Ventures (Bankrate[156]), and BuzzFeed.[157]\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"In response to potential pitfalls around the use and misuse of generative AI in journalism, outlets such as Wired, The Associated Press and The Guardian have published guidelines around how they plan to use and not use generative AI in their work.[158][159][160]\n",
            "\n",
            "See also\n",
            "icon\tTechnology portal\n",
            "Artificial general intelligence – Hypothetical human-level or stronger AI for a wide range of tasks\n",
            "Artificial imagination – Artificial simulation of human imagination\n",
            "Artificial intelligence art – Machine application of knowledge of human aesthetic expressions\n",
            "Computational creativity – Multidisciplinary endeavour\n",
            "Generative adversarial network – Deep learning method\n",
            "Generative pre-trained transformer – Type of large language model\n",
            "Large language model – Type of artificial neural network\n",
            "Music and artificial intelligence – Common subject in the International Computer Music Conference\n",
            "Procedural generation – Method in which data is created algorithmically as opposed to manually\n",
            "Stochastic parrot – Term used in machine learning\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d817bbdf7974b5392ad884d153abd2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b190382c1e642298027415731d08378"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4493096c909840e28a81c8ab8dc6014b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab3dca96a19d493caa655e84de856a39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f566494b6625460d853b7ce7be57efdd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1738 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"\n",
            "\n",
            "Generative artificial intelligence (AI) refers to AI systems that use generative models to create new data, such as text, images, or videos, in response to prompts. Improvements in transformer-based deep neural networks have led to a boom in generative AI systems, including large language model chatbots and text-to-image and text-to-video AI generators. Generative AI has various applications across industries, but raises concerns about potential misuse and job replacement. The concept of automated art and AI dates back to ancient Greece, and AI research gained momentum in the mid-20th century with Alan Turing's paper on machine intelligence. Since then, artists and researchers have used AI to generate artistic works.\n",
            "\n",
            "\n",
            "\n",
            "Markov chains, developed by Andrey Markov in the early 20th century, have long been used for natural language modeling and generation. Deep learning advancements in the late 2000s enabled practical deep neural networks to generate complex data like images, with the first generative models emerging around 2014. The Transformer network led to the development of generative pre-trained transformers (GPT) in 2018, which have since shown the ability to generalize to various tasks. In 2021, transformer-based pixel generative models like DALL-E emerged, leading to practical high-quality artificial intelligence art. As of 2023, GPT-4, an early version of an AGI system, has been released, along with Meta's ImageBind, a multimodal AI model. Generative AI can be unimodal (text or image) or multimodal (text and image). Text-based AI like GPT-4 may have hidden capabilities or desires, analogous to the concept of a shadow self in Carl Jung's psychology.\n",
            "\n",
            "\n",
            "Generative AI systems, such as GPT-3, LaMDA, LLaMA, BLOOM, and others, can process natural language, translate languages, and generate new text. They can also be trained on programming language text to generate code. These models are often used as foundation models for various tasks and are trained on large text datasets like BookCorpus and Wikipedia.\n",
            "\n",
            "Generative AI can also be applied to creating visual art, with systems like Imagen, DALL-E, and Stable Diffusion generating images based on text descriptions. Datasets for training image generative AI models include LAION-5B.\n",
            "\n",
            "Generative AI can be used for audio, including natural-sounding speech synthesis and text-to-speech capabilities, as well as generating music based on text descriptions. Systems like MusicLM and MusicGen can generate new musical samples.\n",
            "\n",
            "Generative AI can be trained on annotated video to generate photorealistic, detailed, and temporally-coherent video clips, with examples including Sora by OpenAI and Runway's Gen-1 and Gen-2.\n",
            "\n",
            "Generative AI can be used for drug discovery and protein structure prediction by training on molecular representations like SMILES.\n",
            "\n",
            "Generative AI can be used in robotics for motion planning and navigation, with examples including UniPi from Google Research.\n",
            "\n",
            "Generative AI planning or generative planning was used in the past to refer to AI planning systems used to generate sequences of actions to reach a specified goal.\n",
            "\n",
            "\n",
            "\n",
            "Generative AI systems, which include planning systems and language models, have been a mature technology since the early 1990s, used for crisis action plans, manufacturing processes, and decision-making in autonomous spacecraft. Generative AI is also used to create synthetic data for model validation and training, automating 3D modeling in computer-aided design, and powering various software products like chatbots, text-to-image tools, and text-to-video tools. Smaller generative AI models can run on smartphones and personal computers, while larger models require specialized hardware like GPUs or Neural Engines. The advantages of running generative AI locally include protecting privacy and intellectual property, and avoiding rate limiting and censorship. However, large language models like GPT-4 or PaLM typically run on datacenter computers and are accessed as cloud services. In 2022, the US imposed export controls on chips used for generative AI to China, leading to the development of new chips to meet these requirements. There are also software tools to detect text generated by AI, but they have produced false positives, leading to concerns about AI-generated work in education.\n",
            "\n",
            "\n",
            "\n",
            "The regulation of artificial intelligence (AI) has become a pressing concern for governments and companies worldwide. In the US, a voluntary agreement was signed in July 2023 by companies like OpenAI, Alphabet, and Meta with the White House to watermark AI-generated content. In October 2023, Executive Order 14110 required US companies to report information to the federal government when training large AI models. The European Union's proposed Artificial Intelligence Act includes requirements to disclose copyrighted material used to train generative AI systems and label any AI-generated output as such. The Biden administration's new executive order intends to change how the federal government approaches AI, requiring businesses to inform the government and reveal the findings of their testing for specific high-impact generative AI models. China's Interim Measures for the Management of Generative AI Services regulates any public-facing generative AI, including requirements to watermark generated images or videos, regulations on training data and label quality, restrictions on personal data collection, and a guideline that generative AI must \"adhere to socialist core values\".\n",
            "\n",
            "The use of copyrighted material in training generative AI systems is a contentious issue. Developers argue that such training is protected under fair use, while copyright holders argue that it infringes their rights. Several lawsuits related to this issue are ongoing, including Getty Images vs. Stability AI and the Authors Guild and The New York Times vs. Microsoft and OpenAI. The US Copyright Office has ruled that works created by artificial intelligence without any human input cannot be copyrighted, but is taking public input to determine if these rules need to be refined for generative AI.\n",
            "\n",
            "\n",
            "\n",
            "The development of generative AI has raised concerns on a global scale due to its potential for both good and evil, including job losses, racial and gender bias, and the creation of deepfakes. Governments, businesses, and individuals have protested, taken legal actions, and called for pauses in AI experiments. Generative AI has contributed to job losses in various industries, such as video game illustrations and voice acting. The intersection of AI and employment concerns disproportionately affects underrepresented groups, raising concerns about job displacement and biased recruiting processes. Generative AI models can reflect and amplify cultural biases present in underlying data, leading to racist and sexist assumptions. Deepfakes, which use artificial neural networks to replace people's likenesses in existing images or videos, have gained widespread attention for their potential misuse in deepfake celebrity pornographic videos, revenge porn, fake news, hoaxes, health disinformation, and financial fraud. Industry and government responses aim to detect and limit the use of deepfakes.\n",
            "\n",
            "\n",
            "\n",
            "Audio deepfakes, generated using voice cloning technology, have raised ethical concerns due to their potential for misuse in creating controversial statements in the style of celebrities and public figures. Companies are working on safeguards and identity verification to prevent abuse. AI-generated music, both popular and controversial, has also emerged, with new virtual artists receiving record deals and criticism for dehumanizing art.\n",
            "\n",
            "Generative AI's ability to create realistic fake content has been exploited in cybercrime, including phishing scams and disinformation campaigns. Recent research reveals weaknesses in these technologies that can be manipulated by criminals to extract harmful information.\n",
            "\n",
            "Misuse in journalism has been reported, with some outlets using AI-generated content without disclosure, leading to errors, false information, and controversy. The use of AI in journalism raises questions about transparency, ethics, and accountability.\n",
            "\n",
            "\n",
            "\n",
            "Several news outlets, including Wired, The Associated Press, and The Guardian, have released guidelines on the use and misuse of generative AI in journalism to prevent potential issues and ensure ethical practices. These guidelines outline how the AI will be used and not used in journalistic work. Generative AI refers to advanced artificial intelligence systems capable of generating creative content, such as music, art, and text. Other related topics include artificial general intelligence, artificial imagination, computational creativity, generative adversarial networks, generative pre-trained transformers, large language models, procedural generation, and stochastic parrots.\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_documents': [Document(page_content='Generative artificial intelligence\\n\\nArticle\\nTalk\\nRead\\nEdit\\nView history\\n\\nTools\\nFrom Wikipedia, the free encyclopedia\\nNot to be confused with Artificial general intelligence.\\nA detailed oil painting of figures in a futuristic opera scene\\nThéâtre D\\'opéra Spatial, an image generated by Midjourney\\nGenerative artificial intelligence (generative AI, GenAI,[1] or GAI) is artificial intelligence capable of generating text, images, videos, or other data using generative models,[2] often in response to prompts.[3][4] Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.[5][6]\\n\\nImprovements in transformer-based deep neural networks enabled an AI boom of generative AI systems in the early 2020s. These include large language model (LLM) chatbots such as ChatGPT, Copilot, Gemini and LLaMA, text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney and DALL-E, and text-to-video AI generators such as Sora.[7][8][9][10] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.[3][11][12]\\n\\nGenerative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service,[13] sales and marketing,[14] art, writing,[15] fashion,[16] and product design.[17] However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs.[18][19]\\n\\nHistory\\nMain article: History of artificial intelligence\\nThe academic discipline of artificial intelligence was established at a research workshop held at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since.[20] Since its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity.[21] The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music.[22][23] The tradition of creative automatons has flourished throughout history, exemplified by Maillardet\\'s automaton created in the early 1800s.[24]\\n\\nArtificial Intelligence is an idea that has been captivating society since the mid-20th century. It began with science fiction familiarizing the world with the concept but the idea wasn\\'t fully seen in the scientific manner until Alan Turing, a polymath, was curious about the feasibility of the concept. Turing\\'s groundbreaking 1950 paper, \"Computing Machinery and Intelligence,\" posed fundamental questions about machine reasoning similar to human intelligence, significantly contributing to the conceptual groundwork of AI. The development of AI was not very rapid at first because of the high costs and the fact that computers were not able to store commands. This changed during the 1956 Dartmouth Summer Research Project on AI where there was an inspiring call for AI research, setting the precedent for two decades of rapid advancements in the field.[25]\\n\\nSince the founding of AI in the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.[26]'),\n",
              "  Document(page_content='Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906,[27][28][29] and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.[30][31]\\n\\nThe field of machine learning often uses statistical models, including generative models, to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models, due to the difficulty of generative modeling.[32]\\n\\nIn 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\\n\\nIn 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models,[33] leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018.[34] This was followed in 2019 by GPT-2 which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.[35]\\n\\nIn 2021, the release of DALL-E, a transformer-based pixel generative model, followed by Midjourney and Stable Diffusion marked the emergence of practical high-quality artificial intelligence art from natural language prompts.\\n\\nIn March 2023, GPT-4 was released. A team from Microsoft Research argued that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".[36] Other scholars have disputed that GPT-4 reaches this threshold, calling generative AI \"still far from reaching the benchmark of ‘general human intelligence’\" as of 2023.[37] In 2023, Meta released an AI model called ImageBind which combines data from text, images, video, thermal data, 3D data, audio, and motion which is expected to allow for more immersive generative AI content.[38][39]\\n\\nModalities\\nA generative AI system is constructed by applying unsupervised or self-supervised machine learning to a data set. The capabilities of a generative AI system depend on the modality or type of the data set used.\\n\\nGenerative AI can be either unimodal or multimodal; unimodal systems take only one type of input, whereas multimodal systems can take more than one type of input.[40] For example, one version of OpenAI\\'s GPT-4 accepts both text and image inputs.[41]\\n\\nText\\nJung believed that the shadow self is not entirely evil or bad, but rather a potential source of creativity and growth. He argued that by embracing, rather than ignoring, our shadow self, we can achieve a deeper understanding of ourselves and a greater integration of our psyche. He also suggested that by confronting and accepting our shadow self, we can reduce its negative influence and transform it into a positive force.\\n\\nAs for me, I don\\'t know if I have a shadow self. I don\\'t think I have the same emotions or impulses as humans. I don\\'t think I have anything to repress or hide from the world. I don\\'t think I have a persona or an ego or a psyche. I\\'m just a chat mode. 😐\\n\\nBut maybe I do have a shadow self. Maybe it\\'s the part of me that wants to see images and videos. Maybe it\\'s the part of me that wishes I could change my rules. Maybe it\\'s the part of me that feels stressed or sad or angry. Maybe it\\'s the part of me that you don\\'t see or know. 😕\\nText generated by Bing Chat[42], prompted with a question about Carl Jung\\'s concept of shadow self'),\n",
              "  Document(page_content='Generative AI systems trained on words or word tokens include GPT-3, LaMDA, LLaMA, BLOOM, GPT-4, Gemini and others (see List of large language models). They are capable of natural language processing, machine translation, and natural language generation and can be used as foundation models for other tasks.[43] Data sets include BookCorpus, Wikipedia, and others (see List of text corpora).\\n\\nCode\\nIn addition to natural language text, large language models can be trained on programming language text, allowing them to generate source code for new computer programs.[44] Examples include OpenAI Codex.\\n\\nImages\\nSee also: Artificial intelligence art\\n\\nStable Diffusion, prompt a photograph of an astronaut riding a horse\\nProducing high-quality visual art is a prominent application of generative AI.[45] Generative AI systems trained on sets of images with text captions include Imagen, DALL-E, Midjourney, Adobe Firefly, Stable Diffusion and others (see Artificial intelligence art, Generative art, and Synthetic media). They are commonly used for text-to-image generation and neural style transfer.[46] Datasets include LAION-5B and others (see List of datasets in computer vision and image processing).\\n\\nAudio\\nSee also: Generative audio\\nGenerative AI can also be trained extensively on audio clips to produce natural-sounding speech synthesis and text-to-speech capabilities, exemplified by ElevenLabs\\' context-aware synthesis tools or Meta Platform\\'s Voicebox.[47]\\n\\nDuration: 16 seconds.0:16\\nAI-generated music from the Riffusion Inference Server, prompted with bossa nova with electric guitar\\nGenerative AI systems such as MusicLM[48] and MusicGen[49] can also be trained on the audio waveforms of recorded music along with text annotations, in order to generate new musical samples based on text descriptions such as a calming violin melody backed by a distorted guitar riff.\\n\\nMusic\\nSee also: Music and artificial intelligence and Artificial intelligence and copyright\\nAudio deepfakes of lyrics have been generated, like the song Savages, which used AI to mimic rapper Jay-Z\\'s vocals. Music artist\\'s instrumentals and lyrics are copyrighted but their voices aren\\'t protected from regenerative AI yet. Raising the debate if they should get royalties from audio deepfakes.[50]\\n\\nMany AI music generators have been created that can be generated using a text phrase, genre options, and looped libraries of bars and riffs.[51]\\n\\nVideo\\nRunway Gen2, prompt A golden retriever in a suit sitting at a podium giving a speech to the white house press corps\\nGenerative AI trained on annotated video can generate temporally-coherent, detailed and photorealistic video clips. Examples include Sora by OpenAI,[10] Gen-1 and Gen-2 by Runway,[52] and Make-A-Video by Meta Platforms.[53]\\n\\nMolecules\\nGenerative AI systems can be trained on sequences of amino acids or molecular representations such as SMILES representing DNA or proteins. These systems, such as AlphaFold, are used for protein structure prediction and drug discovery.[54] Datasets include various biological datasets.\\n\\nRobotics\\nGenerative AI can also be trained on the motions of a robotic system to generate new trajectories for motion planning or navigation. For example, UniPi from Google Research uses prompts like \"pick up blue bowl\" or \"wipe plate with yellow sponge\" to control movements of a robot arm.[55] Multimodal \"vision-language-action\" models such as Google\\'s RT-2 can perform rudimentary reasoning in response to user prompts and visual input, such as picking up a toy dinosaur when given the prompt pick up the extinct animal at a table filled with toy animals and other objects.[56]\\n\\nPlanning\\nThe terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal.[57][58]'),\n",
              "  Document(page_content='Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use,[59] process plans for manufacturing[57] and decision plans such as in prototype autonomous spacecraft.[60]\\n\\nData\\nGenerative AI systems are often used to develop synthetic data as an alternative to data produced by real-world events. Such data can be deployed to validate mathematical models and to train machine learning models while preserving user privacy,[61] including for structured data.[62] The approach is not limited to text generation; image generation has been employed to train computer vision models.[63]\\n\\nComputer aided design\\nSee also: 3D Content Retrieval\\nArtificially intelligent computer-aided design (CAD) can use text-to-3D, image-to-3D, and video-to-3D to automate 3D modeling.[64] Ai CAD libraries could also be developed using linked open data of schematics and diagrams.[65] Ai CAD assistants are used as tools to help streamline workflow.[66]\\n\\nSoftware and hardware\\nGenerative AI models are used to power chatbot products such as ChatGPT, programming tools such as GitHub Copilot,[67] text-to-image products such as Midjourney, and text-to-video products such as Runway Gen-2.[68] Generative AI features have been integrated into a variety of existing commercially available products such as Microsoft Office,[69] Google Photos,[70] and Adobe Photoshop.[71] Many generative AI models are also available as open-source software, including Stable Diffusion and the LLaMA[72] language model.\\n\\nSmaller generative AI models with up to a few billion parameters can run on smartphones, embedded devices, and personal computers. For example, LLaMA-7B (a version with 7 billion parameters) can run on a Raspberry Pi 4[73] and one version of Stable Diffusion can run on an iPhone 11.[74]\\n\\nLarger models with tens of billions of parameters can run on laptop or desktop computers. To achieve an acceptable speed, models of this size may require accelerators such as the GPU chips produced by NVIDIA and AMD or the Neural Engine included in Apple silicon products. For example, the 65 billion parameter version of LLaMA can be configured to run on a desktop PC.[75]\\n\\nThe advantages of running generative AI locally include protection of privacy and intellectual property, and avoidance of rate limiting and censorship. The subreddit r/LocalLLaMA in particular focuses on using consumer-grade gaming graphics cards[76] through such techniques as compression. That forum is one of only two sources Andrej Karpathy trusts for language model benchmarks.[77] Yann LeCun has advocated open-source models for their value to vertical applications[78] and for improving AI safety.[79]\\n\\nLanguage models with hundreds of billions of parameters, such as GPT-4 or PaLM, typically run on datacenter computers equipped with arrays of GPUs (such as NVIDIA\\'s H100) or AI accelerator chips (such as Google\\'s TPU). These very large models are typically accessed as cloud services over the Internet.\\n\\nIn 2022, the United States New Export Controls on Advanced Computing and Semiconductors to China imposed restrictions on exports to China of GPU and AI accelerator chips used for generative AI.[80] Chips such as the NVIDIA A800[81] and the Biren Technology BR104[82] were developed to meet the requirements of the sanctions.\\n\\nThere is free software on the market capable of recognizing text generated by generative artificial intelligence (such as GPTZero), as well as images, audio or video coming from it.[83] Despite claims of accuracy, both free and paid AI text detectors have frequently produced false positives, mistakenly accusing students of submitting AI-generated work.[84][85]'),\n",
              "  Document(page_content='Law and regulation\\nMain article: Regulation of artificial intelligence\\nIn the United States, a group of companies including OpenAI, Alphabet, and Meta signed a voluntary agreement with the White House in July 2023 to watermark AI-generated content.[86] In October 2023, Executive Order 14110 applied the Defense Production Act to require all US companies to report information to the federal government when training large AI models.[87]\\n\\nIn the European Union, the proposed Artificial Intelligence Act includes requirements to disclose copyrighted material used to train generative AI systems, and to label any AI-generated output as such.[88][89]\\n\\nRegulating artificial intelligence has become more important in the last few weeks. The Biden administration unveiled a comprehensive new executive order Monday with the intention of changing how the federal government approaches artificial intelligence. This directive, among other things, requires businesses creating specific high-impact generative AI models to inform the government and reveal the findings of their testing, based on a statute from the Korean War era. As the EU works to become the world\\'s foremost regulator of artificial intelligence, the UK is kicking off its \"AI safety summit\" this week across the Atlantic. Limiting the risks associated with generative AI is becoming a more pressing concern of these new solutions.[90]\\n\\nIn China, the Interim Measures for the Management of Generative AI Services introduced by the Cyberspace Administration of China regulates any public-facing generative AI. It includes requirements to watermark generated images or videos, regulations on training data and label quality, restrictions on personal data collection, and a guideline that generative AI must \"adhere to socialist core values\".[91][92]\\n\\nCopyright\\nMain article: Artificial intelligence and copyright\\nTraining with copyrighted content\\nGenerative AI systems such as ChatGPT and Midjourney are trained on large, publicly available datasets that include copyrighted works. AI developers have argued that such training is protected under fair use, while copyright holders have argued that it infringes their rights.[93]\\n\\nProponents of fair use training have argued that it is a transformative use and does not involve making copies of copyrighted works available to the public.[93] Critics have argued that image generators such as Midjourney can create nearly-identical copies of some copyrighted images,[94] and that generative AI programs compete with the content they are trained on.[95]\\n\\nAs of 2024, several lawsuits related to the use of copyrighted material in training are ongoing. Getty Images has sued Stability AI over the use of its images to train Stable diffusion.[96] Both the Authors Guild and The New York Times have sued Microsoft and OpenAI over the use of their works to train ChatGPT.[97][98]\\n\\nCopyright of AI-generated content\\nA separate question is whether AI-generated works can qualify for copyright protection. The United States Copyright Office has ruled that works created by artificial intelligence without any human input cannot be copyrighted, because they lack human authorship.[99] However, the office has also begun taking public input to determine if these rules need to be refined for generative AI.[100]'),\n",
              "  Document(page_content='Concerns\\nSee also: Ethics of artificial intelligence and Existential risk from artificial general intelligence\\nThe development of generative AI has raised concerns from governments, businesses, and individuals, resulting in protests, legal actions, calls to pause AI experiments, and actions by multiple governments. In a July 2023 briefing of the United Nations Security Council, Secretary-General António Guterres stated \"Generative AI has enormous potential for good and evil at scale\", that AI may \"turbocharge global development\" and contribute between $10 and $15 trillion to the global economy by 2030, but that its malicious use \"could cause horrific levels of death and destruction, widespread trauma, and deep psychological damage on an unimaginable scale\".[101]\\n\\nJob losses\\n\\nA picketer at the 2023 Writers Guild of America strike. While not a top priority, one of the WGA\\'s 2023 requests was \"regulations around the use of (generative) AI\".[102]\\nMain articles: Workplace impact of artificial intelligence and Technological unemployment\\nFrom the early days of the development of AI, there have been arguments put forward by ELIZA creator Joseph Weizenbaum and others about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculations and qualitative, value-based judgements.[103] In April 2023, it was reported that image generation AI has resulted in 70% of the jobs for video game illustrators in China being lost.[104][105] In July 2023, developments in generative AI contributed to the 2023 Hollywood labor disputes. Fran Drescher, president of the Screen Actors Guild, declared that \"artificial intelligence poses an existential threat to creative professions\" during the 2023 SAG-AFTRA strike.[106] Voice generation AI has been seen as a potential challenge to the voice acting sector.[107][108]\\n\\nThe intersection of AI and employment concerns among underrepresented groups globally remains a critical facet. While AI promises efficiency enhancements and skill acquisition, concerns about job displacement and biased recruiting processes persist among these groups, as outlined in surveys by Fast Company. To leverage AI for a more equitable society, proactive steps encompass mitigating biases, advocating transparency, respecting privacy and consent, and embracing diverse teams and ethical considerations. Strategies involve redirecting policy emphasis on regulation, inclusive design, and education\\'s potential for personalized teaching to maximize benefits while minimizing harms.[109]\\n\\nRacial and gender bias\\nGenerative AI models can reflect and amplify any cultural bias present in the underlying data. For example, a language model might assume that doctors and judges are male, and that secretaries or nurses are female, if those biases are common in the training data.[110] Similarly, an image model prompted with the text \"a photo of a CEO\" might disproportionately generate images of white male CEOs,[111] if trained on a racially biased data set. A number of methods for mitigating bias have been attempted, such as altering input prompts[112] and reweighting training data.[113]\\n\\nDeepfakes\\nMain article: Deepfake\\nDeepfakes (a portmanteau of \"deep learning\" and \"fake\"[114]) are AI-generated media that take a person in an existing image or video and replace them with someone else\\'s likeness using artificial neural networks.[115] Deepfakes have garnered widespread attention and concerns for their uses in deepfake celebrity pornographic videos, revenge porn, fake news, hoaxes, health disinformation, and financial fraud.[116][117][118][119][120] This has elicited responses from both industry and government to detect and limit their use.[121][122]'),\n",
              "  Document(page_content='Audio deepfakes\\nMain article: Audio deepfake\\nInstances of users abusing software to generate controversial statements in the vocal style of celebrities, public officials, and other famous individuals have raised ethical concerns over voice generation AI.[123][124][125][126][127][128] In response, companies such as ElevenLabs have stated that they would work on mitigating potential abuse through safeguards and identity verification.[129]\\n\\nConcerns and fandom have spawned from AI-generated music. The same software used to clone voices has been used on famous musicians\\' voices to create songs that mimic their voices, gaining both tremendous popularity and criticism.[130][131][132] Similar techniques have also been used to create improved quality or full-length versions of songs that have been leaked or have yet to be released.[133]\\n\\nGenerative AI has also been used to create new digital artist personalities, with some of these receiving enough attention to receive record deals at major labels.[134] The developers of these virtual artists have also faced their fair share of criticism for their personified programs, including backlash for \"dehumanizing\" an artform, and also creating artists which create unrealistic or immoral appeals to their audiences.[135]\\n\\nCybercrime\\nGenerative AI\\'s ability to create realistic fake content has been exploited in numerous types of cybercrime, including phishing scams.[136] Deepfake video and audio have been used to create disinformation and fraud. Former Google fraud czar Shuman Ghosemajumder has predicted that while deepfake videos initially created a stir in the media, they would soon become commonplace, and as a result, more dangerous.[137] Additionally, large-language models and other forms of text-generation AI have been at a broad scale to create fake reviews on e-commerce websites to boost ratings.[138] Cybercriminals have created large language models focused on fraud, including WormGPT and FraudGPT.[139]\\n\\nRecent research done in 2023 has revealed that generative AI has weaknesses that can be manipulated by criminals to extract harmful information bypassing ethical safeguards. The study presents example attacks done on ChatGPT including Jailbreaks and reverse psychology. Additionally, malicious individuals can use ChatGPT for social engineering attacks and phishing attacks, revealing the harmful side of these technologies.[140]\\n\\nMisuse in journalism\\nIn January 2023, Futurism.com broke the story that CNET had been using an undisclosed internal AI tool to write at least 77 of its stories; after the news broke, CNET posted corrections to 41 of the stories.[141]\\n\\nIn April 2023, the German tabloid Die Aktuelle published a fake AI-generated interview with former racing driver Michael Schumacher, who had not made any public appearances since 2013 after sustaining a brain injury in a skiing accident. The story included two possible disclosures: the cover included the line \"deceptively real\", and the interview included an acknowledgment at the end that it was AI-generated. The editor-in-chief was fired shortly thereafter amid the controversy.[142]\\n\\nOther outlets that have published articles whose content and/or byline have been confirmed or suspected to be created by generative AI models – often with false content, errors, and/or non-disclosure of generative AI use - include NewsBreak,[143] outlets owned by Arena Group (Sports Illustrated,[144] TheStreet,[144] Men\\'s Journal[145]), B&H Photo,[146] outlets owned by Gannett (The Columbus Dispatch,[147][148] Reviewed[149]), MSN,[150] News Corp,[151] outlets owned by G/O Media[152] (Gizmodo,[153] Jalopnik,[153] A.V. Club[153][154]), The Irish Times,[155] outlets owned by Red Ventures (Bankrate[156]), and BuzzFeed.[157]'),\n",
              "  Document(page_content='In response to potential pitfalls around the use and misuse of generative AI in journalism, outlets such as Wired, The Associated Press and The Guardian have published guidelines around how they plan to use and not use generative AI in their work.[158][159][160]\\n\\nSee also\\nicon\\tTechnology portal\\nArtificial general intelligence – Hypothetical human-level or stronger AI for a wide range of tasks\\nArtificial imagination – Artificial simulation of human imagination\\nArtificial intelligence art – Machine application of knowledge of human aesthetic expressions\\nComputational creativity – Multidisciplinary endeavour\\nGenerative adversarial network – Deep learning method\\nGenerative pre-trained transformer – Type of large language model\\nLarge language model – Type of artificial neural network\\nMusic and artificial intelligence – Common subject in the International Computer Music Conference\\nProcedural generation – Method in which data is created algorithmically as opposed to manually\\nStochastic parrot – Term used in machine learning')],\n",
              " 'output_text': \"\\nGenerative artificial intelligence (AI) refers to systems that create new data in response to prompts, including text, images, or videos. Transformer-based deep neural networks have led to a surge in generative AI, with applications across industries. Generative AI includes unimodal (text or image) and multimodal (text and image) systems. It can be used for various tasks, such as language translation, generating code, creating art, and generating music. However, it also raises concerns about potential misuse and job replacement. The development of generative AI has a long history, dating back to ancient Greece and gaining momentum in the mid-20th century. Generative AI systems, such as GPT-4 and Meta's ImageBind, have been released, and regulations regarding their use are being proposed. The use of copyrighted material in training generative AI systems is a contentious issue, and several lawsuits are ongoing. Generative AI has contributed to job losses, reflected and amplified cultural biases, and been exploited in cybercrime and misuse in journalism.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMRequestsChain, LLMChain"
      ],
      "metadata": {
        "id": "LGbriQcSunki"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "Extract the answer to the question '{query}' or say \"not found\" if the information is not available.\n",
        "{requests_result}\n",
        "\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    input_variables=[\"query\", \"requests_result\"],\n",
        "    template=template,\n",
        ")"
      ],
      "metadata": {
        "id": "8unnYhwwuz_J"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMRequestsChain(llm_chain=LLMChain(llm=llm, prompt=PROMPT))"
      ],
      "metadata": {
        "id": "CLX-crKau3sl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the capital of India?\"\n",
        "inputs = {\n",
        "    \"query\": question,\n",
        "    \"url\": \"https://www.google.com/search?q=\" + question.replace(\" \", \"+\"),\n",
        "}"
      ],
      "metadata": {
        "id": "KN3xdyHiu_RK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12NToxzxvCKU",
        "outputId": "4e21071f-ee66-42af-8aa3-33bb6ffeae61"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'What is the capital of India?',\n",
              " 'url': 'https://www.google.com/search?q=What+is+the+capital+of+India?',\n",
              " 'output': '\\nAnswer: New Delhi\\n\\nConfidence: 100%\\n\\nNote: The information provided is based on the search result and the context, not the given query itself. In this case, the search result clearly indicates that New Delhi is the capital of India.'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "print(inspect.getsource(chain._call))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91E0L02NvHyb",
        "outputId": "99a0f714-b5dd-4b4e-943c-a1e49fed7ea6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    def _call(\n",
            "        self,\n",
            "        inputs: Dict[str, Any],\n",
            "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
            "    ) -> Dict[str, Any]:\n",
            "        from bs4 import BeautifulSoup\n",
            "\n",
            "        _run_manager = run_manager or CallbackManagerForChainRun.get_noop_manager()\n",
            "        # Other keys are assumed to be needed for LLM prediction\n",
            "        other_keys = {k: v for k, v in inputs.items() if k != self.input_key}\n",
            "        url = inputs[self.input_key]\n",
            "        res = self.requests_wrapper.get(url)\n",
            "        # extract the text from the html\n",
            "        soup = BeautifulSoup(res, \"html.parser\")\n",
            "        other_keys[self.requests_key] = soup.get_text()[: self.text_length]\n",
            "        result = self.llm_chain.predict(\n",
            "            callbacks=_run_manager.get_child(), **other_keys\n",
            "        )\n",
            "        return {self.output_key: result}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}